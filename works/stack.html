<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../css/style.css">
	<link rel="icon" href="../techimg/logo_icon.gif">
	<title>David Santiano</title>
</head>

<body>
	<nav class="sidebar">
		<header>David Santiano</header>
		<a href="../about/index.html" id="about">About</a>
		<a href="../index.html" id="projects">Projects</a>
	</nav>
	<article class="content">
		<h1>stack.</h1>
		2016/Assistive Tech
		<img class="project_image" src="../techimg/stack_1.jpg">
		<p>
			stack. is a working prototype for a device that can help people with visual disabilities to create
			simple 3D models using the tactility of Legoes. Using computer vision via OpenCV, Unity3D, and a Lego
			board, the user can prototype and then 3D print simple cube-based models that they create layer by layer.
			Here is a quick video:
		</p>
		<iframe src="https://player.vimeo.com/video/188582518" width="1000" height="558" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
		<h1>How it works</h1>
		<p>
			I used a Processing 3.0 flavor of OpenCV to do color detection on a grid-divided Lego board. If there was a Lego detected within one of 
			the squares then a signal was sent to Unity3D via OSC that a Lego is now occupying that portion of the grid, and a 3D cube was then
			rendered in the relevant square on the field in Unity3D.
		</p>
		<p>
			Here is the prototype interface:
		</p>		
		<img class = "project_image" src = "../techimg/stack_4.PNG">
		<p>
			The implementation is still a bit simple, but I am currently working on implementing a more robust and 
			accessible interface, mainly adding audio cues and programming the Unity3D portion out into a standalone
			application.
		</p>
		<img class = "project_image" src = "../techimg/stack_3.PNG">
		<p>

		</p>
	</article>
</body>

</html>